{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7023c2",
   "metadata": {},
   "source": [
    "\n",
    "# Khipus.ai\n",
    "## Applied Statistics with Python\n",
    "### Inferential Statistics (Predictions): Normal distribution, Central Limit Theorem (CLT), confidence intervals and margin of error, T-distribution.\n",
    "<span>© Copyright Notice 2025, Khipus.ai - All Rights Reserved.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "744656e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns # Seaborn is a Python data visualization library based on matplotlib for making easy and beautiful data visualizations.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634ae84",
   "metadata": {},
   "source": [
    "\n",
    "## Standard Normal Distribution\n",
    "The normal distribution, also known as the Gaussian distribution, is a bell-shaped curve that is symmetric about the mean. It is defined by its mean (μ) and standard deviation (σ).\n",
    "\n",
    "Note: The Standard Normal Distribution has a mean of zero and a standard deviation of one.​\n",
    "\n",
    "\n",
    "### Example:\n",
    "Below is an example of how to simulate and visualize a Normal Standard distribution Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate normal distribution\n",
    "# Generate 10,000 random samples from a normal distribution with mean (loc) 0 and standard deviation (scale) 1\n",
    "#size = number of samples\n",
    "normal_samples = np.random.normal(loc=0, scale=1, size=10000)\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 5))  # Create a new figure with a specified size\n",
    "# Plot a histogram of the normal samples with a kernel density estimate (adds a KDE curve to the histogram) and 30 bins\n",
    "sns.histplot(normal_samples, kde=True, bins=30)\n",
    "plt.title('Normal Distribution (μ=0, σ=1)')  # Set the title of the plot\n",
    "plt.xlabel('Value')  # Set the label for the x-axis\n",
    "plt.ylabel('Frequency')  # Set the label for the y-axis\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0a5e1",
   "metadata": {},
   "source": [
    "### Simulating Binomial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f883509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate binomial distribution\n",
    "# Generate 10,000 random samples from a binomial distribution \n",
    "binom_samples = np.random.binomial(n=10, p=0.5, size=10000) #with 10 trials and probability of success 0.5 (flipping a coin)| size=number of samples\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 5))  # Create a new figure with a specified size\n",
    "sns.histplot(binom_samples, kde=False, bins=30)  # Plot a histogram of the binomial samples without a KDE curve and with 30 bins\n",
    "plt.title('Binomial Distribution (n=10, p=0.5)')  # Set the title of the plot\n",
    "plt.xlabel('Number of Successes')  # Set the label for the x-axis\n",
    "plt.ylabel('Frequency')  # Set the label for the y-axis\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b876e19",
   "metadata": {},
   "source": [
    "\n",
    "## Central Limit Theorem (CLT)\n",
    "The Central Limit Theorem states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the population's distribution.\n",
    "\n",
    "### Example:\n",
    "\n",
    "\n",
    "For The example we will use the dataset `data_dev.csv` contains information about developers survey, including their yearly compensation and their plans to use AI. Below is a brief description of the key columns in the dataset:\n",
    "\n",
    "- `converted_comp_yearly`: The yearly compensation of the developers in USD.\n",
    "- `plans_to_use_ai`: The developers' plans to use AI, categorized as 'Using', 'Plan to use', etc.\n",
    "\n",
    "The dataset is used to perform various statistical analyses, including hypothesis testing and confidence interval calculations.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af6c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev_survey = pd.read_csv('data_dev.csv')# Load the data from the CSV file\n",
    "data_dev_survey.head()# Display the first few rows of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f18175",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "This code simulates and visualizes the sampling distribution of the mean using data from a population (converted_comp_yearly column). Here's a summary of what it does:\n",
    "\n",
    "Population: Takes salary data (converted_comp_yearly) as the population.\n",
    "\n",
    "Sampling: Repeatedly extracts 1000 random samples, each with 50 data points, from the population.\n",
    "\n",
    "Calculate Means: Calculates the mean of each sample and stores it.\n",
    "\n",
    "Histogram Plot: Displays the distribution of these sample means in a histogram, showing a bell-shaped curve (Central Limit Theorem).\n",
    "The result illustrates how sample means are distributed, even when sampling repeatedly from the population.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e932e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think of our data as a population to draw (extract) from\n",
    "population = data_dev_survey['converted_comp_yearly'].dropna().values\n",
    "\n",
    "# Generate a large sample from the 'converted_comp_yearly' column\n",
    "# Parameters\n",
    "sample_size = 50 \n",
    "num_samples = 1000 # Number of samples to draw (extract) from the population\n",
    "\n",
    "# Set a seed to make code reproducible\n",
    "np.random.seed(2025)\n",
    "\n",
    "# Simulate sampling distribution of the mean\n",
    "sample_means = []# Create an empty list to store the sample means\n",
    "for _ in range(num_samples):# Loop through the number of samples to draw\n",
    "    sample = np.random.choice(population, sample_size)# Draw a sample of size 50 from the population\n",
    "    sample_means.append(np.mean(sample))# Calculate the sample mean and append it to the list\n",
    "\n",
    "# Plot the sampling distribution of the sample means\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(sample_means, bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.title('Sampling Distribution of the Mean (Sample Size = 50)')\n",
    "plt.xlabel('Sample Mean')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce23e3e6",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "Hypothesis testing is a fundamental concept in statistics that allows researchers to make conclusions based on sample data. It begins with formulating a null hypothesis, which states that there is no effect or difference. The alternative hypothesis suggests otherwise. By determining a significance level, researchers can assess whether to reject the null hypothesis based on the evidence provided by the sample data.\n",
    "\n",
    "Null Hypothesis (H₀): The population mean (Average) compensation is equal to 85000\n",
    "\n",
    "Alternative hypothesis (Ha): The population mean (Average) is greater than 85000 (the hypothesized mean) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd9464d",
   "metadata": {},
   "source": [
    "## t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sample t-test checking for evidence that mu compensation > 85000\n",
    "salary_mean = 85000 # Hypothesized population mean\n",
    "t_stat, p_value = stats.ttest_1samp( # Perform a one-sample t-test.\n",
    "  data_dev_survey['converted_comp_yearly'].dropna(), # Sample data.The Null Hypothesis (H₀) is implicitly represented in the ttest_1samp function. \n",
    " # Null Hypothesis (H₀): The population mean (Average) compensation is equal to 85000\n",
    " popmean = salary_mean,# Population mean\n",
    "  alternative='greater')# Alternative hypothesis (Ha): the population mean (Average) is greater than the hypothesized mean\n",
    "\n",
    "alpha = 0.05 # Significance level (α)The probability of making a Type I error (False Positive), commonly set at 0.05.\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b18b64",
   "metadata": {},
   "source": [
    "Analyzing the results:\n",
    "\n",
    "T-statistic: 2.387 indicates the number of standard deviations the sample mean is away from the hypothesized population mean (85000).\n",
    "\n",
    "P-value: 0.0086. Since the p-value is less than 0.05, we reject the null hypothesis, indicating the mean compensation is likely greater than 85000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffccd3",
   "metadata": {},
   "source": [
    "### Two-sample t-test\n",
    "\n",
    "Null Hypothesis (H₀): There is no difference in compensation between those currently using AI and those planning to use AI.\n",
    "\n",
    "Alternative Hypothesis (H₁): There is a difference in compensation between those currently using AI and those planning to use AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6653ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-sample t-test comparing compensation across plans_to_use_ai groups\n",
    "# Checking for a difference\n",
    "\n",
    "# Extract compensation data for those currently using AI\n",
    "using = data_dev_survey[data_dev_survey['plans_to_use_ai'] == 'Using']['converted_comp_yearly'].dropna()\n",
    "\n",
    "# Extract compensation data for those planning to use AI\n",
    "plan_to_use = data_dev_survey[data_dev_survey['plans_to_use_ai'] == 'Plan to use']['converted_comp_yearly'].dropna()\n",
    "\n",
    "# Perform a two-sample t-test to compare the means of the two groups\n",
    "# 'equal_var=False' indicates that we do not assume equal population variances\n",
    "t_stat, p_value = stats.ttest_ind(using, plan_to_use, equal_var=False)\n",
    "\n",
    "# Print the t-statistic and p-value\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3f625",
   "metadata": {},
   "source": [
    "Analyzing the results:\n",
    "\n",
    "Since the p-value (0.353) is greater than the common significance level (< 0.05), we fail to reject the null hypothesis. This suggests there is no significant difference in compensation between those currently using AI and those planning to use AI with the data that we have data_dev.csv dataset from 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
